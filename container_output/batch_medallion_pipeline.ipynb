{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0430b29d-ec2a-4452-942d-c33c8fce8534",
   "metadata": {},
   "source": [
    "# NYC Taxi Data Pipeline with Delta Lake (Medallion Architecture)\n",
    "\n",
    "This notebook implements a **batch data pipeline** using Apache Spark and Delta Lake, structured around the **Medallion Architecture**:\n",
    "\n",
    "- **Bronze Layer (Raw Ingestion)**  \n",
    "  - Ingests raw NYC Taxi Parquet data into Delta format.  \n",
    "  - Preserves the original schema for reproducibility and auditability.  \n",
    "  - Provides a foundation for downstream transformations.\n",
    "\n",
    "- **Silver Layer (Cleaned & Enriched)**  \n",
    "  - Applies business rules and data quality filters (removes invalid trips, handles nulls).  \n",
    "  - Derives key metrics such as trip duration, tip percentage, fare per mile, and pickup hour.  \n",
    "  - Adds categorical labels (e.g., payment type) for interpretability.  \n",
    "  - Produces a curated dataset ready for analytics.\n",
    "\n",
    "- **Gold Layer (Business KPIs)**  \n",
    "  - Aggregates Silver data into business‑ready insights:  \n",
    "    - Hourly trip volume (demand analysis).  \n",
    "    - Daily revenue (financial KPI).  \n",
    "    - Tip behavior by payment type (customer behavior).  \n",
    "    - Fare efficiency by zone (spatial analysis).  \n",
    "  - Each output is stored as a Delta table, partitioned for scalability.\n",
    "\n",
    "- **Governance & Maintenance**  \n",
    "  - Uses **VACUUM** to safely remove obsolete files after retention period.  \n",
    "  - Demonstrates **time travel** to query historical versions.  \n",
    "  - Tracks operations with **DESCRIBE HISTORY** for audit and compliance.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449bb640-b15c-4855-a421-a1ab03f02336",
   "metadata": {},
   "source": [
    "# **Environment Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "17ebdcb3-d0c2-42d9-a9be-aff6395a19c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkSession with Delta Lake extensions (Spark 4.0)\n",
    "from pyspark.sql import SparkSession\n",
    "from delta import configure_spark_with_delta_pip\n",
    "\n",
    "spark.stop()  # ensure clean reset\n",
    "\n",
    "builder = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"batch-medallion-delta-ingestion\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    .config(\"spark.executor.memory\", \"2g\")\n",
    ")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c3df95-c414-41c8-bc38-5882799653c0",
   "metadata": {},
   "source": [
    "# **Bronze Layer: Ingesting Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c8c607cc-f0fc-4a78-9e71-4780d5ba4616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#  Ingest raw NYC Taxi data and persist as Delta table\n",
    "df_bronze = (\n",
    "    spark.read.format(\"parquet\")\n",
    "    .load(\"/project/yellow_tripdata_2025-01.parquet\")\n",
    ")\n",
    "\n",
    "(df_bronze.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .save(\"/project/delta/bronze/trips\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2c516a79-ba6e-4f6a-ad07-4a2cf9abe351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- payment_type_label: string (nullable = false)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tip_percentage: double (nullable = true)\n",
      " |-- fare_per_mile: double (nullable = true)\n",
      " |-- total_fees: double (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- pickup_hour: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = false)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = false)\n",
      " |-- Airport_fee: double (nullable = false)\n",
      " |-- cbd_congestion_fee: double (nullable = false)\n",
      " |-- total_amount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Viewing the schema of the dataframe\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3c0886cb-66b6-430f-9649-40c352981c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "3475226"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data profiling - row counts\n",
    "df = spark.read.format(\"delta\").load(\"/project/delta/bronze/trips\")\n",
    "df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "58bd9a7e-0fe5-4b37-9f43-139272e4ab19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:=================================>                        (4 + 3) / 7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|cbd_congestion_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "|       0|                   0|                    0|         540149|            0|    540149|            540149|           0|           0|           0|          0|    0|      0|         0|           0|                    0|           0|              540149|     540149|                 0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#Nulls per column\n",
    "from pyspark.sql import functions as F\n",
    "df.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "85e53b9c-edcb-4f2d-9f41-65690400ba74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:=========================================>                (5 + 2) / 7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+---------------------+------------------+--------------------+-------------------+-------------------+\n",
      "|summary|          VendorID|   passenger_count|    trip_distance|       RatecodeID|store_and_fwd_flag|     PULocationID|      DOLocationID|      payment_type|       fare_amount|             extra|            mta_tax|        tip_amount|       tolls_amount|improvement_surcharge|      total_amount|congestion_surcharge|        Airport_fee| cbd_congestion_fee|\n",
      "+-------+------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+---------------------+------------------+--------------------+-------------------+-------------------+\n",
      "|  count|           3475226|           2935077|          3475226|          2935077|           2935077|          3475226|           3475226|           3475226|           3475226|           3475226|            3475226|           3475226|            3475226|              3475226|           3475226|             2935077|            2935077|            3475226|\n",
      "|   mean|1.7854283433652949|1.2978589658806226|5.855126178843539|2.482534529758504|              NULL|165.1915757421244|164.12517689497028|1.0366229419324096| 17.08180276045484| 1.317736691081386| 0.4780990502488183|2.9598127862758044|0.44930810255221726|   0.9547945658785968|25.611291697280986|   2.225237191392253|0.12391105923285829|0.48340928043240927|\n",
      "| stddev|0.4263282213054428|0.7507502754804695|564.6015996346273|11.63277200403341|              NULL|64.52948262355422| 69.40168629828547|0.7013334099485089|463.47291781729996|1.8615086824178437|0.13746226502954365| 3.779681153612477| 2.0025818139908114|   0.2781937753492549| 463.6584784502166|  0.9039932093176657|0.47250898141473596|0.36193065974945354|\n",
      "|    min|                 1|                 0|              0.0|                1|                 N|                1|                 1|                 0|            -900.0|              -7.5|               -0.5|             -86.0|            -126.94|                 -1.0|            -901.0|                -2.5|              -1.75|              -0.75|\n",
      "|    max|                 7|                 9|        276423.57|               99|                 Y|              265|               265|                 5|         863372.12|              15.0|               10.5|             400.0|             170.94|                  1.0|         863380.37|                 2.5|               6.75|               0.75|\n",
      "+-------+------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+---------------------+------------------+--------------------+-------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#Basic distributions\n",
    "df.describe().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a079188a-3fd2-4172-9e58-7a93e9d9e3d9",
   "metadata": {},
   "source": [
    "##### **Trip calculation and profiling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c172016e-61d2-4bc9-b679-c41727cf50cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+\n",
      "|summary|trip_duration_minutes|\n",
      "+-------+---------------------+\n",
      "|  count|              3475226|\n",
      "|   mean|    15.01811561799608|\n",
      "| stddev|    38.71358219498149|\n",
      "|    min|  -51472.316666666666|\n",
      "|    max|    5626.316666666667|\n",
      "+-------+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Validation / Exploration Step: \n",
    "# Here we calculate trip duration in minutes using pickup and dropoff timestamps. \n",
    "# We use unix_timestamp to safely convert timestamp_ntz fields into epoch seconds. \n",
    "# This allows us to subtract times and derive trip duration. \n",
    "# The describe() summary provides validation of logical consistency (mean, min, max), \n",
    "# helping us detect anomalies such as negative durations or excessively long trips.\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "df = df.withColumn(\"trip_duration_minutes\",\n",
    "    (F.unix_timestamp(\"tpep_dropoff_datetime\") -\n",
    "     F.unix_timestamp(\"tpep_pickup_datetime\")) / 60)\n",
    "\n",
    "df.select(\"trip_duration_minutes\").describe().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f1b145-cc60-4066-86e8-2c1f4e25d28d",
   "metadata": {},
   "source": [
    "##### **Hourly pickup distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ba11bd23-233e-43d6-99b0-af04a5294231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|pickup_hour| count|\n",
      "+-----------+------+\n",
      "|          0| 93417|\n",
      "|          1| 64484|\n",
      "|          2| 43929|\n",
      "|          3| 28492|\n",
      "|          4| 20033|\n",
      "|          5| 22551|\n",
      "|          6| 50026|\n",
      "|          7|102581|\n",
      "|          8|141305|\n",
      "|          9|142877|\n",
      "|         10|148316|\n",
      "|         11|160076|\n",
      "|         12|175432|\n",
      "|         13|186144|\n",
      "|         14|202289|\n",
      "|         15|213694|\n",
      "|         16|217051|\n",
      "|         17|253518|\n",
      "|         18|267951|\n",
      "|         19|221055|\n",
      "+-----------+------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Exploration Step: \n",
    "# This block extracts the pickup hour from each trip timestamp. \n",
    "# Grouping by hour and counting trips reveals demand patterns across the day. \n",
    "# It validates timestamp parsing and provides exploratory insight into peak taxi activity. \n",
    "# These results can later inform business logic such as surge pricing or driver allocation.\n",
    "df.withColumn(\"pickup_hour\", F.hour(\"tpep_pickup_datetime\")) \\\n",
    "  .groupBy(\"pickup_hour\") \\\n",
    "  .count() \\\n",
    "  .orderBy(\"pickup_hour\") \\\n",
    "  .show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df983e2-3f65-4e46-8eea-e3375f99dbe4",
   "metadata": {},
   "source": [
    "# **Data Transformation and Manipulation with Apache Spark (Silver)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2c6482f8-2f85-4be4-998d-83821f62ef5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Transform and enrich Bronze data (duration, tip %, fare/mile, pickup hour)\n",
    "from pyspark.sql import functions as F\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Load Bronze data\n",
    "df_bronze = spark.read.format(\"delta\").load(\"/project/delta/bronze/trips\")\n",
    "\n",
    "df_silver = (\n",
    "    df_bronze\n",
    "    .withColumn(\"trip_duration_minutes\",\n",
    "        (F.unix_timestamp(\"tpep_dropoff_datetime\") - F.unix_timestamp(\"tpep_pickup_datetime\")) / 60\n",
    "    )\n",
    "    .withColumn(\"tip_percentage\",\n",
    "        F.when(F.col(\"fare_amount\") > 0, (F.col(\"tip_amount\") / F.col(\"fare_amount\")) * 100)\n",
    "    )\n",
    "    .withColumn(\"fare_per_mile\",\n",
    "        F.when(F.col(\"trip_distance\") > 0, F.col(\"fare_amount\") / F.col(\"trip_distance\"))\n",
    "    )\n",
    "    .withColumn(\"pickup_hour\", F.hour(\"tpep_pickup_datetime\"))\n",
    ")\n",
    "\n",
    "# Deduplicate source to avoid multiple matches\n",
    "df_silver = df_silver.dropDuplicates(\n",
    "    [\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"PULocationID\", \"DOLocationID\"]\n",
    ")\n",
    "\n",
    "# Path to Silver table\n",
    "silver_path = \"/project/delta/silver/trips\"\n",
    "\n",
    "try:\n",
    "    # Load existing Silver table\n",
    "    silver_table = DeltaTable.forPath(spark, silver_path)\n",
    "\n",
    "    # Perform MERGE (upsert)\n",
    "    (\n",
    "        silver_table.alias(\"target\")\n",
    "        .merge(\n",
    "            df_silver.alias(\"source\"),\n",
    "            \"target.VendorID = source.VendorID AND \\\n",
    "             target.tpep_pickup_datetime = source.tpep_pickup_datetime AND \\\n",
    "             target.tpep_dropoff_datetime = source.tpep_dropoff_datetime AND \\\n",
    "             target.PULocationID = source.PULocationID AND \\\n",
    "             target.DOLocationID = source.DOLocationID\"\n",
    "        )\n",
    "        .whenMatchedUpdateAll()\n",
    "        .whenNotMatchedInsertAll()\n",
    "        .execute()\n",
    "    )\n",
    "except:\n",
    "    # If Silver table doesn't exist yet, initialize it\n",
    "    df_silver.write.format(\"delta\").save(silver_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "44e91789-8b94-4a3c-a07f-bb9fb31e37b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MERGE logic for late-arriving data is Delta-ready. No late batch loaded in this run.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Silver Layer: Placeholder for handling late-arriving data using MERGE (Delta Lake ready)\n",
    "\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Reference Silver Delta table\n",
    "silver_table = DeltaTable.forPath(spark, \"/project/delta/silver/trips\")\n",
    "\n",
    "# Placeholder logic — no late-arriving data loaded yet\n",
    "# This block is Delta-ready and can be activated once late data is available\n",
    "\n",
    "print(\"MERGE logic for late-arriving data is Delta-ready. No late batch loaded in this run.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d588fb51-6eea-4e3f-acff-f7474dbf3110",
   "metadata": {},
   "source": [
    "#### **1) Filtering Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "28690299-8a75-4ac2-ae68-e8b09bcdd7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "2840016"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# We selectively apply filtering techniques that align with our schema and business logic:\n",
    "# Basic condition filtering: Used to remove trips with negative duration or fare amounts.\n",
    "# Compound condition filtering: Used to combine multiple business rules (e.g., duration and fare).\n",
    "# Example: df.filter((F.col(\"fare_amount\") >= 0) & (F.col(\"trip_duration_minutes\") > 0))\n",
    "# Filtering by list of values: Reserved for future use with categorical fields like RatecodeID or payment_type.\n",
    "# Date range filtering: Will be applied later in Gold layer for time-based slicing.\n",
    "# These choices ensure our Silver layer enforces business logic without replicating unnecessary cookbook examples.\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# 1. Remove trips with negative or zero duration\n",
    "df = df.filter(F.col(\"trip_duration_minutes\") > 0)\n",
    "\n",
    "# 2. Remove trips with negative fare amounts\n",
    "df = df.filter(F.col(\"fare_amount\") >= 0)\n",
    "\n",
    "# 3. Remove trips with null passenger_count\n",
    "df = df.filter(F.col(\"passenger_count\").isNotNull())\n",
    "\n",
    "# 4. Remove trips with zero distance\n",
    "# (ensures only valid trips are retained)\n",
    "df = df.filter(F.col(\"trip_distance\") > 0)\n",
    "\n",
    "# Show row count after filtering to validate impact\n",
    "df.count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae98651f-e5e3-4eb7-be59-0d695fa97644",
   "metadata": {},
   "source": [
    "#### **2) Handling Null Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5c871ee9-88c8-47d6-8b63-cac478c1d92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with nulls in RatecodeID, PULocationID, DOLocationID, payment_type\n",
    "df = df.dropna(subset=[\"RatecodeID\", \"PULocationID\", \"DOLocationID\", \"payment_type\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d7e2e5c4-3c80-477d-974e-379bf1779dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill nulls in store_and_fwd_flag with 'N' (default for no forwarding)\n",
    "df = df.fillna({\"store_and_fwd_flag\": \"N\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "021fdf25-2c0a-407a-ae87-61e8a30bb643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill nulls in optional fee columns with 0\n",
    "fee_columns = [\"congestion_surcharge\", \"Airport_fee\", \"cbd_congestion_fee\"]\n",
    "df = df.fillna({col: 0.0 for col in fee_columns})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "368ceef9-6ffa-4922-a364-b474d2ddbffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 98:====================================>                     (5 + 3) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+---------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|cbd_congestion_fee|trip_duration_minutes|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+---------------------+\n",
      "|       0|                   0|                    0|              0|            0|         0|                 0|           0|           0|           0|          0|    0|      0|         0|           0|                    0|           0|                   0|          0|                 0|                    0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Show updated null counts\n",
    "df.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c046a6-2d75-455f-ada3-2f052bdc6570",
   "metadata": {},
   "source": [
    "### **3) Basic Transformations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ea6ef26a-8647-4eb2-ba3c-ceebbccfd048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tip percentage = (tip_amount / fare_amount) * 100\n",
    "df = df.withColumn(\"tip_percentage\", (F.col(\"tip_amount\") / F.col(\"fare_amount\")) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "05036906-826f-46d0-879f-2d47aee69e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fare per mile = fare_amount / trip_distance\n",
    "df = df.withColumn(\"fare_per_mile\", F.col(\"fare_amount\") / F.col(\"trip_distance\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8cc90091-9d4b-4bb6-835d-f9b46a578025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total fees (excluding fare) = extra + mta_tax + tolls_amount + improvement_surcharge + congestion_surcharge + Airport_fee + cbd_congestion_fee\n",
    "df = df.withColumn(\"total_fees\",\n",
    "    F.col(\"extra\") +\n",
    "    F.col(\"mta_tax\") +\n",
    "    F.col(\"tolls_amount\") +\n",
    "    F.col(\"improvement_surcharge\") +\n",
    "    F.col(\"congestion_surcharge\") +\n",
    "    F.col(\"Airport_fee\") +\n",
    "    F.col(\"cbd_congestion_fee\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "99677001-cafb-413a-879a-c345530096ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only apply if you suspect duplicate trips\n",
    "df = df.dropDuplicates([\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"PULocationID\", \"DOLocationID\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c77c0247-8495-4bde-9187-5e6a5334cde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by pickup time\n",
    "df_sorted = df.orderBy(\"tpep_pickup_datetime\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "98b27046-7a17-4006-b326-920a6170177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data type normalization\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Cast categorical IDs to IntegerType for clarity and efficiency\n",
    "df = df.withColumn(\"RatecodeID\", F.col(\"RatecodeID\").cast(IntegerType()))\n",
    "df = df.withColumn(\"payment_type\", F.col(\"payment_type\").cast(IntegerType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "38ae1414-51bf-4205-bb02-746fac6a246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical Labelling\n",
    "# Map payment_type codes to human-readable labels\n",
    "#Makes aggregations and dashboards much more interpretable.\n",
    "\n",
    "payment_type_map = {\n",
    "    1: \"Credit Card\",\n",
    "    2: \"Cash\",\n",
    "    3: \"No Charge\",\n",
    "    4: \"Dispute\",\n",
    "    5: \"Unknown\",\n",
    "    6: \"Voided Trip\"\n",
    "}\n",
    "\n",
    "df = df.withColumn(\"payment_type_label\",\n",
    "    F.when(F.col(\"payment_type\") == 1, \"Credit Card\")\n",
    "     .when(F.col(\"payment_type\") == 2, \"Cash\")\n",
    "     .when(F.col(\"payment_type\") == 3, \"No Charge\")\n",
    "     .when(F.col(\"payment_type\") == 4, \"Dispute\")\n",
    "     .when(F.col(\"payment_type\") == 5, \"Unknown\")\n",
    "     .when(F.col(\"payment_type\") == 6, \"Voided Trip\")\n",
    "     .otherwise(\"Other\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "dae9144f-7e47-48d9-b501-c08c851d7cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'tpep_pickup_datetime',\n",
       " 'tpep_dropoff_datetime',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'RatecodeID',\n",
       " 'store_and_fwd_flag',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'payment_type',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'congestion_surcharge',\n",
       " 'Airport_fee',\n",
       " 'cbd_congestion_fee',\n",
       " 'trip_duration_minutes',\n",
       " 'tip_percentage',\n",
       " 'fare_per_mile',\n",
       " 'total_fees',\n",
       " 'payment_type_label']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking columns\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bea89ef1-d88d-47cc-b3ef-1e669ba07366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Safe fare per mile\n",
    "#Derives the fare_per_mile metric by dividing fare amount by trip distance, with safe handling to avoid divide‑by‑zero errors.\n",
    "\n",
    "df = df.withColumn(\"fare_per_mile\",\n",
    "    F.when(F.col(\"trip_distance\") > 0, F.col(\"fare_amount\") / F.col(\"trip_distance\"))\n",
    "     .otherwise(None)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "38f0737f-ebf6-4050-88c9-a3fd2e5d08e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates tip_percentage relative to fare amount, ensuring rows with zero fares are handled gracefully.\n",
    "df = df.withColumn(\"tip_percentage\",\n",
    "    F.when(F.col(\"fare_amount\") > 0, (F.col(\"tip_amount\") / F.col(\"fare_amount\")) * 100)\n",
    "     .otherwise(None)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "61d01e36-9be7-48ad-b627-4a3fd80016cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adds a pickup_hour column by extracting the hour of day from the pickup timestamp, enabling hourly demand analysis.\n",
    "\n",
    "from pyspark.sql.functions import hour\n",
    "\n",
    "df = df.withColumn(\"pickup_hour\", hour(\"tpep_pickup_datetime\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f5dffb52-cabf-4c7f-bc0b-e675ce92e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(\n",
    "    \"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\",\n",
    "    \"passenger_count\", \"trip_distance\", \"RatecodeID\", \"payment_type\", \"payment_type_label\",\n",
    "    \"fare_amount\", \"tip_amount\", \"tip_percentage\", \"fare_per_mile\", \"total_fees\",\n",
    "    \"PULocationID\", \"DOLocationID\", \"pickup_hour\", \"store_and_fwd_flag\",\n",
    "    \"extra\", \"mta_tax\", \"tolls_amount\", \"improvement_surcharge\",\n",
    "    \"congestion_surcharge\", \"Airport_fee\", \"cbd_congestion_fee\", \"total_amount\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1639561a-0747-455c-ba9d-d48db29cd891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'tpep_pickup_datetime',\n",
       " 'tpep_dropoff_datetime',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'RatecodeID',\n",
       " 'payment_type',\n",
       " 'payment_type_label',\n",
       " 'fare_amount',\n",
       " 'tip_amount',\n",
       " 'tip_percentage',\n",
       " 'fare_per_mile',\n",
       " 'total_fees',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'pickup_hour',\n",
       " 'store_and_fwd_flag',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'congestion_surcharge',\n",
       " 'Airport_fee',\n",
       " 'cbd_congestion_fee',\n",
       " 'total_amount']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displays the current list of DataFrame columns to validate schema after transformations and confirm inclusion of derived fields like pickup_hour, fare_per_mile, and tip_percentage.\n",
    "df.columns   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2817be10-c7d8-45df-a403-a1e86c4123f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 103:==========================================>              (6 + 2) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------+------------------+-----------+----------+------------------+------------------+------------------+------------+------------+-----------+------------------+-----+-------+------------+---------------------+--------------------+-----------+------------------+------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|payment_type|payment_type_label|fare_amount|tip_amount|    tip_percentage|     fare_per_mile|        total_fees|PULocationID|DOLocationID|pickup_hour|store_and_fwd_flag|extra|mta_tax|tolls_amount|improvement_surcharge|congestion_surcharge|Airport_fee|cbd_congestion_fee|total_amount|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------+------------------+-----------+----------+------------------+------------------+------------------+------------+------------+-----------+------------------+-----+-------+------------+---------------------+--------------------+-----------+------------------+------------+\n",
      "|       2| 2024-12-31 21:33:43|  2024-12-31 21:39:00|              2|         1.12|         1|           2|              Cash|        7.9|       0.0|               0.0| 7.053571428571428|               2.5|         179|           7|         21|                 N|  1.0|    0.5|         0.0|                  1.0|                 0.0|        0.0|               0.0|        10.4|\n",
      "|       2| 2025-01-01 00:00:57|  2025-01-01 00:24:49|              1|         9.81|         1|           1|       Credit Card|       41.5|       5.0|12.048192771084338| 4.230377166156982|              9.25|         138|         189|          0|                 N|  6.0|    0.5|         0.0|                  1.0|                 0.0|       1.75|               0.0|       55.75|\n",
      "|       2| 2025-01-01 00:02:20|  2025-01-01 00:03:34|              1|         0.12|         1|           2|              Cash|        3.7|       0.0|               0.0|30.833333333333336|               5.0|         249|         249|          0|                 N|  1.0|    0.5|         0.0|                  1.0|                 2.5|        0.0|               0.0|         8.7|\n",
      "|       2| 2025-01-01 00:02:23|  2025-01-01 00:13:19|              1|         2.55|         1|           1|       Credit Card|       14.2|      3.84|27.042253521126764| 5.568627450980392|               5.0|         229|         238|          0|                 N|  1.0|    0.5|         0.0|                  1.0|                 2.5|        0.0|               0.0|       23.04|\n",
      "|       1| 2025-01-01 00:02:29|  2025-01-01 00:38:23|              3|         20.1|         2|           1|       Credit Card|       70.0|      16.0|22.857142857142858|3.4825870646766166|11.940000000000001|         132|         151|          0|                 N| 1.75|    0.5|        6.94|                  1.0|                 0.0|       1.75|               0.0|       96.19|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------+------------------+-----------+----------+------------------+------------------+------------------+------------+------------+-----------+------------------+-----+-------+------------+---------------------+--------------------+-----------+------------------+------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb0bc73-38d9-40e8-bdad-79cd552a5c00",
   "metadata": {},
   "source": [
    "# **Data Management with Delta Lake (Gold)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "58776ff8-636e-4e03-bc8b-9d97dbb73e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "\n",
    "# Hourly Trip Volume (pickup_hour aggregation)\n",
    "df_silver = spark.read.format(\"delta\").load(\"/project/delta/silver/trips\")\n",
    "\n",
    "df_gold_trip_volume = (\n",
    "    df_silver.groupBy(F.to_date(\"tpep_pickup_datetime\").alias(\"pickup_date\"), \"pickup_hour\")\n",
    "             .agg(F.count(\"*\").alias(\"trip_count\"))\n",
    ")\n",
    "\n",
    "(df_gold_trip_volume.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .partitionBy(\"pickup_date\")\n",
    "    .save(\"/project/delta/gold/trip_volume_hourly\"))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "daf38e64-a8c7-41f0-b286-2b1ba6840015",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#  Daily Revenue using total_amount\n",
    "df_gold_revenue = (\n",
    "    df_silver.groupBy(F.to_date(\"tpep_pickup_datetime\").alias(\"pickup_date\"))\n",
    "             .agg(F.sum(\"total_amount\").alias(\"daily_revenue\"))\n",
    ")\n",
    "\n",
    "(df_gold_revenue.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .partitionBy(\"pickup_date\")\n",
    "    .save(\"/project/delta/gold/revenue_daily\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "647f99f0-1e31-4c8d-b51f-da2e78afa55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Tip Behavior by Payment Type (categorical aggregation)\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Reload Silver table\n",
    "df_silver = spark.read.format(\"delta\").load(\"/project/delta/silver/trips\")\n",
    "\n",
    "# Add payment_type_label column\n",
    "df_silver = df_silver.withColumn(\n",
    "    \"payment_type_label\",\n",
    "    F.when(F.col(\"payment_type\") == 1, \"Credit Card\")\n",
    "     .when(F.col(\"payment_type\") == 2, \"Cash\")\n",
    "     .when(F.col(\"payment_type\") == 3, \"No Charge\")\n",
    "     .when(F.col(\"payment_type\") == 4, \"Dispute\")\n",
    "     .when(F.col(\"payment_type\") == 5, \"Unknown\")\n",
    "     .when(F.col(\"payment_type\") == 6, \"Voided Trip\")\n",
    "     .otherwise(\"Other\")\n",
    ")\n",
    "\n",
    "# Now perform the aggregation\n",
    "df_gold_tip_behavior = (\n",
    "    df_silver.groupBy(\"payment_type_label\")\n",
    "             .agg(F.avg(\"tip_percentage\").alias(\"avg_tip_percentage\"))\n",
    ")\n",
    "\n",
    "(df_gold_tip_behavior.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .save(\"/project/delta/gold/tip_behavior\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6972c13e-4550-42cf-a465-9d6a6dc4c60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "## Fare Efficiency by Zone (Spatial Aggregation)\n",
    "df_gold_fare_efficiency = (\n",
    "    df.groupBy(\"PULocationID\", \"DOLocationID\")\n",
    "      .agg(F.avg(\"fare_per_mile\").alias(\"avg_fare_per_mile\"))\n",
    ")\n",
    "\n",
    "(df_gold_fare_efficiency\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .save(\"/project/gold/fare_efficiency\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdb3c10-5368-401b-989d-2ed7ecbf625d",
   "metadata": {},
   "source": [
    "# **Delta Lake Maintenance and Governance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7a9829ae-d0ed-4c42-b59f-15b803a7cd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 0 files and directories in a total of 1 directories.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+---------------------+--------------+-----------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|cbd_congestion_fee|trip_duration_minutes|tip_percentage|    fare_per_mile|pickup_hour|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+---------------------+--------------+-----------------+-----------+\n",
      "|       2| 2025-01-17 18:08:04|  2025-01-17 18:19:55|           NULL|          0.0|      NULL|              NULL|         161|         186|           0|      13.22|  0.0|    0.5|       0.0|         0.0|                  1.0|       17.97|                NULL|       NULL|              0.75|                11.85|           0.0|             NULL|         18|\n",
      "|       2| 2025-01-17 18:16:20|  2025-01-17 18:33:22|           NULL|         0.01|      NULL|              NULL|         234|         143|           0|      21.09|  0.0|    0.5|       0.0|         0.0|                  1.0|       25.84|                NULL|       NULL|              0.75|   17.033333333333335|           0.0|           2109.0|         18|\n",
      "|       1| 2025-01-17 18:01:26|  2025-01-17 18:22:49|           NULL|          6.7|      NULL|              NULL|         231|         141|           0|       25.7|  0.0|    0.5|       0.0|         0.0|                  1.0|       30.45|                NULL|       NULL|              0.75|   21.383333333333333|           0.0|3.835820895522388|         18|\n",
      "|       2| 2025-01-17 18:51:18|  2025-01-17 19:11:39|           NULL|          0.0|      NULL|              NULL|         234|         239|           0|      -4.75|  0.0|    0.5|       0.0|         0.0|                  1.0|        6.37|                NULL|       NULL|              0.75|                20.35|          NULL|             NULL|         18|\n",
      "|       2| 2025-01-17 18:14:51|  2025-01-17 18:25:51|           NULL|          0.0|      NULL|              NULL|         193|         179|           0|      10.04|  0.0|    0.5|       0.0|         0.0|                  1.0|       11.54|                NULL|       NULL|               0.0|                 11.0|           0.0|             NULL|         18|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+---------------------+--------------+-----------------+-----------+\n",
      "only showing top 5 rows\n",
      "+-------+-----------------------+------+--------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+--------+---------+-----------+-----------------+-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation   |operationParameters                                                                                                                                                                                                                                                                                                                                                                                                          |job |notebook|clusterId|readVersion|isolationLevel   |isBlindAppend|operationMetrics                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+--------+---------+-----------+-----------------+-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|5      |2026-01-28 05:38:10.432|NULL  |NULL    |VACUUM END  |{status -> COMPLETED}                                                                                                                                                                                                                                                                                                                                                                                                        |NULL|NULL    |NULL     |4          |SnapshotIsolation|true         |{numDeletedFiles -> 0, numVacuumedDirectories -> 1}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |NULL        |Apache-Spark/4.0.0 Delta-Lake/4.0.0|\n",
      "|4      |2026-01-28 05:38:07.032|NULL  |NULL    |VACUUM START|{retentionCheckEnabled -> true, defaultRetentionMillis -> 604800000, specifiedRetentionMillis -> 604800000}                                                                                                                                                                                                                                                                                                                  |NULL|NULL    |NULL     |3          |SnapshotIsolation|true         |{numFilesToDelete -> 0, sizeOfDataToDelete -> 0}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |NULL        |Apache-Spark/4.0.0 Delta-Lake/4.0.0|\n",
      "|3      |2026-01-28 05:27:38.35 |NULL  |NULL    |MERGE       |{predicate -> [\"((((VendorID#18711 = VendorID#18686) AND (tpep_pickup_datetime#18712 = tpep_pickup_datetime#18687)) AND (tpep_dropoff_datetime#18713 = tpep_dropoff_datetime#18688)) AND ((PULocationID#18718 = PULocationID#18693) AND (DOLocationID#18719 = DOLocationID#18694)))\"], matchedPredicates -> [{\"actionType\":\"update\"}], notMatchedPredicates -> [{\"actionType\":\"insert\"}], notMatchedBySourcePredicates -> []}|NULL|NULL    |NULL     |2          |Serializable     |false        |{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetBytesRemoved -> 94322221, numTargetDeletionVectorsAdded -> 0, numTargetRowsMatchedUpdated -> 3475226, numTargetRowsMatchedDeleted -> 0, numTargetRowsUpdated -> 3475226, numTargetChangeFilesAdded -> 0, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 40475, numTargetFilesAdded -> 9, numTargetBytesAdded -> 103549635, executionTimeMs -> 81239, materializeSourceTimeMs -> 24633, numTargetRowsInserted -> 0, numTargetDeletionVectorsUpdated -> 0, scanTimeMs -> 15754, numOutputRows -> 3475226, numTargetDeletionVectorsRemoved -> 0, numTargetRowsNotMatchedBySourceUpdated -> 0, numSourceRows -> 3422687, numTargetFilesRemoved -> 4}|NULL        |Apache-Spark/4.0.0 Delta-Lake/4.0.0|\n",
      "|2      |2026-01-27 15:19:25.103|NULL  |NULL    |VACUUM END  |{status -> COMPLETED}                                                                                                                                                                                                                                                                                                                                                                                                        |NULL|NULL    |NULL     |1          |SnapshotIsolation|true         |{numDeletedFiles -> 0, numVacuumedDirectories -> 1}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |NULL        |Apache-Spark/4.0.0 Delta-Lake/4.0.0|\n",
      "|1      |2026-01-27 15:19:20.321|NULL  |NULL    |VACUUM START|{retentionCheckEnabled -> true, defaultRetentionMillis -> 604800000, specifiedRetentionMillis -> 604800000}                                                                                                                                                                                                                                                                                                                  |NULL|NULL    |NULL     |0          |SnapshotIsolation|true         |{numFilesToDelete -> 0, sizeOfDataToDelete -> 0}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |NULL        |Apache-Spark/4.0.0 Delta-Lake/4.0.0|\n",
      "|0      |2026-01-27 13:21:48.787|NULL  |NULL    |WRITE       |{mode -> Overwrite, partitionBy -> []}                                                                                                                                                                                                                                                                                                                                                                                       |NULL|NULL    |NULL     |NULL       |Serializable     |false        |{numFiles -> 4, numRemovedFiles -> 0, numRemovedBytes -> 0, numOutputRows -> 3475226, numOutputBytes -> 94322221}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |NULL        |Apache-Spark/4.0.0 Delta-Lake/4.0.0|\n",
      "+-------+-----------------------+------+--------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+--------+---------+-----------+-----------------+-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. VACUUM: Remove obsolete files older than 7 days (safe retention period)\n",
    "spark.sql(\"VACUUM delta.`/project/delta/silver/trips` RETAIN 168 HOURS\")\n",
    "\n",
    "# 2. Time Travel: Query Silver Layer as of a previous version\n",
    "df_old = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(\"/project/delta/silver/trips\")\n",
    "df_old.show(5)\n",
    "\n",
    "# 3. History: Inspect table versions and operations\n",
    "spark.sql(\"DESCRIBE HISTORY delta.`/project/delta/silver/trips`\").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c6f98b-6205-42c1-9032-058d270ffbef",
   "metadata": {},
   "source": [
    "##### **Checking History**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "401e96a0-b467-4147-919d-27d5de0dffef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+------+--------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+--------+---------+-----------+-----------------+-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation   |operationParameters                                                                                                                                                                                                                                                                                                                                                                                                          |job |notebook|clusterId|readVersion|isolationLevel   |isBlindAppend|operationMetrics                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+--------+---------+-----------+-----------------+-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|5      |2026-01-28 05:38:10.432|NULL  |NULL    |VACUUM END  |{status -> COMPLETED}                                                                                                                                                                                                                                                                                                                                                                                                        |NULL|NULL    |NULL     |4          |SnapshotIsolation|true         |{numDeletedFiles -> 0, numVacuumedDirectories -> 1}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |NULL        |Apache-Spark/4.0.0 Delta-Lake/4.0.0|\n",
      "|4      |2026-01-28 05:38:07.032|NULL  |NULL    |VACUUM START|{retentionCheckEnabled -> true, defaultRetentionMillis -> 604800000, specifiedRetentionMillis -> 604800000}                                                                                                                                                                                                                                                                                                                  |NULL|NULL    |NULL     |3          |SnapshotIsolation|true         |{numFilesToDelete -> 0, sizeOfDataToDelete -> 0}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |NULL        |Apache-Spark/4.0.0 Delta-Lake/4.0.0|\n",
      "|3      |2026-01-28 05:27:38.35 |NULL  |NULL    |MERGE       |{predicate -> [\"((((VendorID#18711 = VendorID#18686) AND (tpep_pickup_datetime#18712 = tpep_pickup_datetime#18687)) AND (tpep_dropoff_datetime#18713 = tpep_dropoff_datetime#18688)) AND ((PULocationID#18718 = PULocationID#18693) AND (DOLocationID#18719 = DOLocationID#18694)))\"], matchedPredicates -> [{\"actionType\":\"update\"}], notMatchedPredicates -> [{\"actionType\":\"insert\"}], notMatchedBySourcePredicates -> []}|NULL|NULL    |NULL     |2          |Serializable     |false        |{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetBytesRemoved -> 94322221, numTargetDeletionVectorsAdded -> 0, numTargetRowsMatchedUpdated -> 3475226, numTargetRowsMatchedDeleted -> 0, numTargetRowsUpdated -> 3475226, numTargetChangeFilesAdded -> 0, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 40475, numTargetFilesAdded -> 9, numTargetBytesAdded -> 103549635, executionTimeMs -> 81239, materializeSourceTimeMs -> 24633, numTargetRowsInserted -> 0, numTargetDeletionVectorsUpdated -> 0, scanTimeMs -> 15754, numOutputRows -> 3475226, numTargetDeletionVectorsRemoved -> 0, numTargetRowsNotMatchedBySourceUpdated -> 0, numSourceRows -> 3422687, numTargetFilesRemoved -> 4}|NULL        |Apache-Spark/4.0.0 Delta-Lake/4.0.0|\n",
      "|2      |2026-01-27 15:19:25.103|NULL  |NULL    |VACUUM END  |{status -> COMPLETED}                                                                                                                                                                                                                                                                                                                                                                                                        |NULL|NULL    |NULL     |1          |SnapshotIsolation|true         |{numDeletedFiles -> 0, numVacuumedDirectories -> 1}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |NULL        |Apache-Spark/4.0.0 Delta-Lake/4.0.0|\n",
      "|1      |2026-01-27 15:19:20.321|NULL  |NULL    |VACUUM START|{retentionCheckEnabled -> true, defaultRetentionMillis -> 604800000, specifiedRetentionMillis -> 604800000}                                                                                                                                                                                                                                                                                                                  |NULL|NULL    |NULL     |0          |SnapshotIsolation|true         |{numFilesToDelete -> 0, sizeOfDataToDelete -> 0}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |NULL        |Apache-Spark/4.0.0 Delta-Lake/4.0.0|\n",
      "|0      |2026-01-27 13:21:48.787|NULL  |NULL    |WRITE       |{mode -> Overwrite, partitionBy -> []}                                                                                                                                                                                                                                                                                                                                                                                       |NULL|NULL    |NULL     |NULL       |Serializable     |false        |{numFiles -> 4, numRemovedFiles -> 0, numRemovedBytes -> 0, numOutputRows -> 3475226, numOutputBytes -> 94322221}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |NULL        |Apache-Spark/4.0.0 Delta-Lake/4.0.0|\n",
      "+-------+-----------------------+------+--------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+--------+---------+-----------+-----------------+-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spark SQL\n",
    "spark.sql(\"DESCRIBE HISTORY delta.`/project/delta/silver/trips`\").show(50, truncate=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c75f8bd-cfa2-4009-a4e6-d49fd9a7ee28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
